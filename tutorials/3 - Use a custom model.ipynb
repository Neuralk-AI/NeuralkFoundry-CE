{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbed1b6",
   "metadata": {},
   "source": [
    "# Using a Custom Model\n",
    "\n",
    "This tutorial demonstrates how to integrate a new model into the Neuralk Foundry-CE and use it as part of a workflow.\n",
    "\n",
    "We begin by explaining how Neuralk Foundry-CE handles models and how to define a custom one. In this example, we wrap the `HistGradientBoostingClassifier` from scikit-learn. This allows the model to be seamlessly inserted into workflows alongside other components.\n",
    "\n",
    "## Creating a Custom Model for Neuralk Foundry\n",
    "\n",
    "To integrate a new model into a Neuralk workflow, you define a **task head** by extending the `BaseTaskHead` class. This component encapsulates how the model is initialized, trained, and used for inference, while ensuring compatibility with Neuralk's workflow system.\n",
    "\n",
    "Below is a template for implementing a custom classifier. It defines the core methods required to:\n",
    "\n",
    "* **Train** it using input features, labels, and fold definitions (`train`)\n",
    "* **Perform inference** on unseen data (`forward`)\n",
    "* **Initialize** the model from a config (`init_model`)\n",
    "* For automated hyperparameter optimization\n",
    "  * **Expose tunable hyperparameters** for automated search (`get_model_params`)\n",
    "\n",
    "This design allows for flexible integration of any framework—whether scikit-learn, PyTorch, XGBoost, or others—within a unified workflow interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "916e0421-60ca-43b3-bd7e-1b8444dc6be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makaroff/Documents/GitHub/NeuralkFoundry-CE/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from neuralk_foundry_ce.models import ClassifierModel\n",
    "\n",
    "\n",
    "class MyClassifier(ClassifierModel):\n",
    "    name = \"my-classifier\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def train(self, X, y, folds, splits):\n",
    "        ...\n",
    "\n",
    "    def forward(self, X, folds, splits):\n",
    "        ...\n",
    "\n",
    "    def init_model(self, config):\n",
    "        self.config = config\n",
    "        self.model = ...\n",
    "\n",
    "    def get_model_params(self, trial, inputs):\n",
    "        return { }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6c407-81eb-4e23-9d62-0067016d2f53",
   "metadata": {},
   "source": [
    "We see here that the signature differs from sklearn estimators. The reason is because some models may have different needs. For example, NN usually need both train and validation sets to train as they control their own overfitting using them. For this reason, the whole dataset is always sent to classifiers along with the folds, a mask of the size of n_samples specifying for each sample if they belong to train, validation, or test. This versatility gives the user all liberty in implementing their model.\n",
    "\n",
    "Since most models will not use this formalism, we also provide a decorator to access a sklearn-like interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9945ac-f512-4367-8302-6d898a8a5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralk_foundry_ce.models import ClassifierModel\n",
    "from neuralk_foundry_ce.utils.splitting import with_masked_split\n",
    "\n",
    "\n",
    "class MyClassifier(ClassifierModel):\n",
    "    name = \"my-classifier\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def init_model(self, config):\n",
    "        self.config = config\n",
    "        self.model = ...\n",
    "\n",
    "    @with_masked_split\n",
    "    def train(self, X, y):\n",
    "        ...\n",
    "\n",
    "    @with_masked_split\n",
    "    def forward(self, X):\n",
    "        ...\n",
    "\n",
    "    def get_fixed_params(self, inputs):\n",
    "        return { }\n",
    "    \n",
    "    def get_model_params(self, trial, inputs):\n",
    "        return { }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cdc6ad-3094-4e70-8df9-0c96d48a2ddb",
   "metadata": {},
   "source": [
    "## Implementing the model wrapper\n",
    "\n",
    "We begin by defining a custom model class. In this example, we use the `HistGradientBoostingClassifier` from scikit-learn, wrapped to be compatible with Neuralk Foundry’s workflow system. This model is well-suited for tabular data and supports both numerical and categorical features natively.\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "| Hyperparameter         | Description                                                                           | Default  | Recommended Range         |\n",
    "| ---------------------- | ------------------------------------------------------------------------------------- | -------- | ------------------------- |\n",
    "| `learning_rate`        | Shrinks the contribution of each tree. Lower values improve generalization.           | `0.1`    | `0.01` to `0.2`           |\n",
    "| `max_iter`             | Number of boosting iterations (trees).                                                | `100`    | `100` to `500`            |\n",
    "| `max_leaf_nodes`       | Maximum number of leaf nodes in each tree. Controls tree complexity.                  | `31`     | `16` to `256`             |\n",
    "| `max_depth`            | Maximum depth of each tree. Overrides `max_leaf_nodes` if set.                        | `None`   | `3` to `10` (if used)     |\n",
    "| `min_samples_leaf`     | Minimum number of samples in each leaf. Prevents overfitting.                         | `20`     | `5` to `100`              |\n",
    "| `l2_regularization`    | L2 penalty applied to leaf values to prevent overfitting.                             | `0.0`    | `0.0` to `1.0`            |\n",
    "| `early_stopping`       | Whether to enable early stopping based on validation loss.                            | `True`   | `True`                    |\n",
    "| `scoring`              | Metric to use for early stopping (e.g., `'loss'`, `'accuracy'`).                      | `'loss'` | Task-dependent            |\n",
    "| `validation_fraction`  | Fraction of training data to set aside for validation when early stopping is enabled. | `0.1`    | `0.1` to `0.3`            |\n",
    "| `n_iter_no_change`     | Number of iterations with no improvement before stopping early.                       | `10`     | `10` to `50`              |\n",
    "| `random_state`         | Controls reproducibility.                                                             | `None`   | Any integer               |\n",
    "| `categorical_features` | Specifies categorical features (or `\"auto\"` for detection).                           | `\"auto\"` | `\"auto\"` or explicit list |\n",
    "\n",
    "As for datasets, inheriting of the `BaseTaskHead` automatically adds the class in our registry. We use this to test that the integration is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf18fa1-e4e5-4418-82c2-e7919ef0a532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered successfully!\n"
     ]
    }
   ],
   "source": [
    "from neuralk_foundry_ce.workflow import get_step_class\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "class HistGradientClassifier(ClassifierModel):\n",
    "    name = \"hist-gb-classifier\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def init_model(self, config):\n",
    "        self.config = config\n",
    "        self.model = HistGradientBoostingClassifier(**config)\n",
    "\n",
    "    @with_masked_split\n",
    "    def train(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    @with_masked_split\n",
    "    def forward(self, X):\n",
    "        self.extras['y_score'] = self.model.predict_proba(X)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def get_fixed_params(self, inputs):\n",
    "        return {\n",
    "            \"early_stopping\": True,\n",
    "            \"scoring\": \"loss\",\n",
    "            \"validation_fraction\": 0.1,\n",
    "            \"n_iter_no_change\": 20,\n",
    "            \"random_state\": 42\n",
    "        }\n",
    "        \n",
    "    def get_model_params(self, trial, inputs):\n",
    "        return {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 100, 500),\n",
    "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 16, 256),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 5, 100),\n",
    "            \"l2_regularization\": trial.suggest_float(\"l2_regularization\", 0.0, 1.0),\n",
    "        }\n",
    "\n",
    "try:\n",
    "    get_step_class(\"hist-gb-classifier\")\n",
    "    print('Model registered successfully!')\n",
    "except ValueError:\n",
    "    print('Failed to register model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfbd6f",
   "metadata": {},
   "source": [
    "Let's define our model. If you read about the structure of our benchmark in this [notebook](1%20-%20Getting%20Started%20with%20Neuralk%20Foundry.ipynb), you will notice that any class implemented in neuralk benchmark is automagically registered and made available for all workflows. After defining our class, we check that it is registered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8ccf3-43f2-4bfd-93c5-b5a6f9b34f0e",
   "metadata": {},
   "source": [
    "# Use it in a workflow\n",
    "Your model is ready to go, you can now use it in any neuralk benchmark workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2dd48c-e991-4ac4-958b-605d79915010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .pipeline {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            justify-content: flex-start;\n",
       "            font-family: sans-serif;\n",
       "            margin-top: 26px;\n",
       "        }\n",
       "        .block-wrapper {\n",
       "            position: relative;\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            align-items: center;\n",
       "            margin: 0 10px;\n",
       "        }\n",
       "        .block-title {\n",
       "            position: absolute;\n",
       "            top: -24px;\n",
       "            font-weight: bold;\n",
       "            text-align: center;\n",
       "        }\n",
       "        .block {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            align-items: center;\n",
       "        }\n",
       "        .group {\n",
       "            border: 2px solid #999;\n",
       "            border-radius: 10px;\n",
       "            background: #f9f9f9;\n",
       "            padding: 8px;\n",
       "        }\n",
       "        .node-container {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            justify-content: center;\n",
       "        }\n",
       "        .node {\n",
       "            display: inline-block;\n",
       "            background: #eaf4ff;\n",
       "            border-radius: 10px;\n",
       "            padding: 8px 12px;\n",
       "            text-align: center;\n",
       "            min-width: 120px;\n",
       "            box-shadow: 1px 1px 3px rgba(0,0,0,0.1);\n",
       "        }\n",
       "        .arrow {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            justify-content: center;\n",
       "            font-size: 20px;\n",
       "            margin: 0 10px;\n",
       "            height: 100%;\n",
       "        }\n",
       "        .step-detail {\n",
       "            margin-top: 30px;\n",
       "            padding: 10px 16px;\n",
       "            border-top: 2px solid #ccc;\n",
       "            font-family: sans-serif;\n",
       "            font-size: 14px;\n",
       "            max-width: 800px;\n",
       "            max-height: none !important;\n",
       "            overflow: visible !important;\n",
       "        }\n",
       "        .step-detail ul {\n",
       "            padding-left: 1em;\n",
       "            margin: 0.3em 0;\n",
       "        }\n",
       "    </style>\n",
       "\n",
       "    <script>\n",
       "        const stepData = {\"0_0\": {\"name\": \"StratifiedShuffleSplitter\", \"description\": \"Stratified shuffle-based data splitter for classification tasks.\", \"inputs\": [{\"name\": \"X\", \"doc\": \"Input features of the dataset\"}, {\"name\": \"y\", \"doc\": \"Target variable to predict\"}, {\"name\": \"fold_index\", \"doc\": \"Index of the train/test split\"}], \"outputs\": [{\"name\": \"splits\", \"doc\": \"Masks for train, validation, and test sets\"}], \"params\": []}, \"1_0\": {\"name\": \"ColumnTypeDetection\", \"description\": \"Detects column types and forwards them to the rest of the pipeline.\", \"inputs\": [{\"name\": \"X\", \"doc\": \"Input features of the dataset\"}, {\"name\": \"y\", \"doc\": \"Target variable to predict\"}], \"outputs\": [{\"name\": \"numerical_features\", \"doc\": \"Names of the numerical feature columns\"}, {\"name\": \"categorical_features\", \"doc\": \"Names of the categorical feature columns\"}, {\"name\": \"text_features\", \"doc\": \"Names of the text feature columns\"}, {\"name\": \"date_features\", \"doc\": \"Names of the date feature columns\"}], \"params\": [{\"name\": \"numerical_features\", \"doc\": \"Names of the numerical feature columns\", \"optional\": true}, {\"name\": \"categorical_features\", \"doc\": \"Names of the categorical feature columns\", \"optional\": true}, {\"name\": \"text_features\", \"doc\": \"Names of the text feature columns\", \"optional\": true}, {\"name\": \"date_features\", \"doc\": \"Names of the date feature columns\", \"optional\": true}]}, \"1_1\": {\"name\": \"CategoricalPreprocessor\", \"description\": \"Preprocessing step for categorical features in tabular data.\", \"inputs\": [{\"name\": \"X\", \"doc\": \"Input features of the dataset\"}, {\"name\": \"y\", \"doc\": \"Target variable to predict\"}, {\"name\": \"categorical_features\", \"doc\": \"Names of the categorical feature columns\"}], \"outputs\": [{\"name\": \"X\", \"doc\": \"Preprocessed input features\"}], \"params\": [{\"name\": \"categorical_encoding\", \"doc\": \"Encoding method for categorical features [onehot, target, integer, none]\", \"optional\": true}, {\"name\": \"categorical_imputation\", \"doc\": \"Imputation strategy for missing categorical values\", \"optional\": true}]}, \"1_2\": {\"name\": \"NumericalPreprocessor\", \"description\": \"Preprocessing step for tabular data with safe handling of datetimes and free-text.\", \"inputs\": [{\"name\": \"X\", \"doc\": \"Input features of the dataset\"}, {\"name\": \"numerical_features\", \"doc\": \"Names of the numerical feature columns\"}], \"outputs\": [{\"name\": \"X\", \"doc\": \"Preprocessed input features\"}], \"params\": [{\"name\": \"numerical_encoding\", \"doc\": \"Encoding method for numerical features [standard, power, none]\", \"optional\": true}, {\"name\": \"numerical_imputation\", \"doc\": \"Imputation strategy for missing numerical values\", \"optional\": true}]}, \"1_3\": {\"name\": \"TfidfVectorizer\", \"description\": \"Encode string columns in a DataFrame using TF-IDF vectorization.\", \"inputs\": [{\"name\": \"X\", \"doc\": \"Input features of the dataset\"}, {\"name\": \"y\", \"doc\": \"Target variable to predict\"}], \"outputs\": [{\"name\": \"X\", \"doc\": \"Input features woth vectorized features\"}], \"params\": []}, \"1_4\": {\"name\": \"LabelEncoder\", \"description\": \"Encode class labels as integers using scikit-learn's LabelEncoder.\", \"inputs\": [{\"name\": \"y\", \"doc\": \"Target variable to predict\"}], \"outputs\": [{\"name\": \"y\", \"doc\": \"Encoded target variable\"}, {\"name\": \"y_classes\", \"doc\": \"Mapping int -> class\"}], \"params\": []}, \"2_0\": {\"name\": \"HistGradientClassifier\", \"description\": \"Base class for predictive task heads in a machine learning workflow.\", \"inputs\": [{\"name\": \"X\", \"doc\": \"Input features of the dataset\"}, {\"name\": \"y\", \"doc\": \"Target variable to predict\"}, {\"name\": \"splits\", \"doc\": \"Masks for train, validation, and test sets\"}, {\"name\": \"metric_to_optimize\", \"doc\": \"Metric to optimize during model selection or hyperparameter tuning\"}, {\"name\": \"y_classes\", \"doc\": \"Original classes before label encoding\"}, {\"name\": \"categorical_features\", \"doc\": \"Names of columns corresponding to categorical features\"}], \"outputs\": [{\"name\": \"y_pred\", \"doc\": \"Predicted target values\"}, {\"name\": \"y_score\", \"doc\": \"Class probability distribution for each sample\"}], \"params\": [{\"name\": \"n_hyperopt_trials\", \"doc\": \"Number of trials attempted for hyperparameter optimization\", \"optional\": true}]}};\n",
       "        window.showStepDetails = function(stepId) {\n",
       "            const step = stepData[stepId];\n",
       "            if (!step) return;\n",
       "\n",
       "            function list(items, optionalKey = false) {\n",
       "                return items.map(f => \n",
       "                    `<li><b>${f.name}</b>: ${f.doc}` +\n",
       "                    (optionalKey && f.optional ? \" <span style='color:gray'>(optional)</span>\" : \"\") +\n",
       "                    \"</li>\"\n",
       "                ).join('');\n",
       "            }\n",
       "\n",
       "            document.getElementById(\"step-detail\").innerHTML = `\n",
       "                <h3>${step.name}</h3>\n",
       "                <p><b>Description:</b> ${step.description}</p>\n",
       "                <div><b>Inputs:</b><ul>${step.inputs.length ? list(step.inputs) : \"<li><i>None</i></li>\"}</ul></div>\n",
       "                <div><b>Outputs:</b><ul>${step.outputs.length ? list(step.outputs) : \"<li><i>None</i></li>\"}</ul></div>\n",
       "                <div><b>Parameters:</b><ul>${step.params.length ? list(step.params, true) : '<li><i>None</i></li>'}</ul></div>\n",
       "            `;\n",
       "        }\n",
       "    </script>\n",
       "\n",
       "    <div class=\"pipeline\">\n",
       "        \n",
       "            <div class=\"block-wrapper\">\n",
       "                <div class=\"block-title\">Splitting</div>\n",
       "                <div class=\"block\">\n",
       "                    <div class=\"node-container\">\n",
       "                        \n",
       "        <div class=\"node\" onclick=\"showStepDetails('0_0')\" style=\"cursor: pointer;\">\n",
       "            <div \n",
       "                style=\"font-weight: bold; margin-bottom: 8px; cursor: help;\" \n",
       "                title=\"Stratified shuffle-based data splitter for classification tasks.\"\n",
       "            >\n",
       "                StratifiedShuffleSplitter\n",
       "            </div>\n",
       "\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Inputs:</b> <span title='Input features of the dataset'>X</span>, <span title='Target variable to predict'>y</span>, <span title='Index of the train/test split'>fold_index</span> <span style='color:gray'>(opt.)</span></div>\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Outputs:</b> <span title='Masks for train, validation, and test sets'>splits</span></div>\n",
       "        </div>\n",
       "        \n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"arrow\">⮕</div>\n",
       "            <div class=\"block-wrapper\">\n",
       "                <div class=\"block-title\">Feature engineering</div>\n",
       "                <div class=\"block group\">\n",
       "                    <div class='node-container'>\n",
       "        <div class=\"node\" onclick=\"showStepDetails('1_0')\" style=\"cursor: pointer;\">\n",
       "            <div \n",
       "                style=\"font-weight: bold; margin-bottom: 8px; cursor: help;\" \n",
       "                title=\"Detects column types and forwards them to the rest of the pipeline.\"\n",
       "            >\n",
       "                ColumnTypeDetection\n",
       "            </div>\n",
       "\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Inputs:</b> <span title='Input features of the dataset'>X</span>, <span title='Target variable to predict'>y</span></div>\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Outputs:</b> <span title='Names of the numerical feature columns'>numerical_features</span>, <span title='Names of the categorical feature columns'>categorical_features</span>, <span title='Names of the text feature columns'>text_features</span>, <span title='Names of the date feature columns'>date_features</span></div>\n",
       "        </div>\n",
       "        </div><div style='height:6px'></div><div class='arrow'>⬇</div><div class='node-container'>\n",
       "        <div class=\"node\" onclick=\"showStepDetails('1_1')\" style=\"cursor: pointer;\">\n",
       "            <div \n",
       "                style=\"font-weight: bold; margin-bottom: 8px; cursor: help;\" \n",
       "                title=\"Preprocessing step for categorical features in tabular data.\"\n",
       "            >\n",
       "                CategoricalPreprocessor\n",
       "            </div>\n",
       "\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Inputs:</b> <span title='Input features of the dataset'>X</span>, <span title='Target variable to predict'>y</span>, <span title='Names of the categorical feature columns'>categorical_features</span> <span style='color:gray'>(opt.)</span></div>\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Outputs:</b> <span title='Preprocessed input features'>X</span></div>\n",
       "        </div>\n",
       "        </div><div style='height:6px'></div><div class='arrow'>⬇</div><div class='node-container'>\n",
       "        <div class=\"node\" onclick=\"showStepDetails('1_2')\" style=\"cursor: pointer;\">\n",
       "            <div \n",
       "                style=\"font-weight: bold; margin-bottom: 8px; cursor: help;\" \n",
       "                title=\"Preprocessing step for tabular data with safe handling of datetimes and free-text.\"\n",
       "            >\n",
       "                NumericalPreprocessor\n",
       "            </div>\n",
       "\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Inputs:</b> <span title='Input features of the dataset'>X</span>, <span title='Names of the numerical feature columns'>numerical_features</span></div>\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Outputs:</b> <span title='Preprocessed input features'>X</span></div>\n",
       "        </div>\n",
       "        </div><div style='height:6px'></div><div class='arrow'>⬇</div><div class='node-container'>\n",
       "        <div class=\"node\" onclick=\"showStepDetails('1_3')\" style=\"cursor: pointer;\">\n",
       "            <div \n",
       "                style=\"font-weight: bold; margin-bottom: 8px; cursor: help;\" \n",
       "                title=\"Encode string columns in a DataFrame using TF-IDF vectorization.\"\n",
       "            >\n",
       "                TfidfVectorizer\n",
       "            </div>\n",
       "\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Inputs:</b> <span title='Input features of the dataset'>X</span>, <span title='Target variable to predict'>y</span></div>\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Outputs:</b> <span title='Input features woth vectorized features'>X</span></div>\n",
       "        </div>\n",
       "        </div><div style='height:6px'></div><div class='arrow'>⬇</div><div class='node-container'>\n",
       "        <div class=\"node\" onclick=\"showStepDetails('1_4')\" style=\"cursor: pointer;\">\n",
       "            <div \n",
       "                style=\"font-weight: bold; margin-bottom: 8px; cursor: help;\" \n",
       "                title=\"Encode class labels as integers using scikit-learn&#x27;s LabelEncoder.\"\n",
       "            >\n",
       "                LabelEncoder\n",
       "            </div>\n",
       "\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Inputs:</b> <span title='Target variable to predict'>y</span></div>\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Outputs:</b> <span title='Encoded target variable'>y</span>, <span title='Mapping int -&gt; class'>y_classes</span></div>\n",
       "        </div>\n",
       "        </div><div style='height:6px'></div>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"arrow\">⮕</div>\n",
       "            <div class=\"block-wrapper\">\n",
       "                <div class=\"block-title\">Classifier</div>\n",
       "                <div class=\"block\">\n",
       "                    <div class=\"node-container\">\n",
       "                        \n",
       "        <div class=\"node\" onclick=\"showStepDetails('2_0')\" style=\"cursor: pointer;\">\n",
       "            <div \n",
       "                style=\"font-weight: bold; margin-bottom: 8px; cursor: help;\" \n",
       "                title=\"Base class for predictive task heads in a machine learning workflow.\"\n",
       "            >\n",
       "                HistGradientClassifier\n",
       "            </div>\n",
       "\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Inputs:</b> <span title='Input features of the dataset'>X</span>, <span title='Target variable to predict'>y</span>, <span title='Masks for train, validation, and test sets'>splits</span>, <span title='Metric to optimize during model selection or hyperparameter tuning'>metric_to_optimize</span>, <span title='Original classes before label encoding'>y_classes</span> <span style='color:gray'>(opt.)</span>, <span title='Names of columns corresponding to categorical features'>categorical_features</span></div>\n",
       "            <div style='font-size: smaller; margin-bottom: 4px'><b>Outputs:</b> <span title='Predicted target values'>y_pred</span>, <span title='Class probability distribution for each sample'>y_score</span></div>\n",
       "        </div>\n",
       "        \n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "            \n",
       "    </div>\n",
       "\n",
       "    <div class=\"step-detail\" id=\"step-detail\">\n",
       "        <b>Click on a step to view its details</b>\n",
       "    </div>\n",
       "\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neuralk_foundry_ce.workflow.use_cases import Classification\n",
    "\n",
    "\n",
    "use_case = Classification()\n",
    "use_case.set_classifier(HistGradientClassifier())\n",
    "use_case.notebook_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64be5785-df20-4c2c-bb57-0c8487cb5a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test ROC AUC 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "data, metrics = use_case.run(X, y)\n",
    "print(f'Final test ROC AUC {metrics[\"hist-gb-classifier\"][\"test_roc_auc\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
